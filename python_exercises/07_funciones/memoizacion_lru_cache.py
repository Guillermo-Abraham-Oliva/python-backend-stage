import os
os.system('clear')

'''
lru_cache es un decorador de la biblioteca est√°ndar de Python (functools).
Se usa para guardar en cach√© los resultados de una funci√≥n y evitar recalcular valores repetidos.

@lru_cache(maxsize=None)

Guarda los valores de las llamadas previas a la funci√≥n en memoria (RAM).
Si la funci√≥n se llama con un valor ya calculado, lo devuelve directamente desde la cach√© en lugar de recalcularlo.
maxsize=None significa que la cach√© no tiene l√≠mite (guarda todos los resultados posibles) esto puede ser un Peligro en backend. Se recomienda usar un l√≠mite: @lru_cache(maxsize=1000)
'''

from functools import lru_cache

@lru_cache(maxsize=None)
def fibonacci_cache(n):
    if n <= 0:
        return 0
    elif n == 1:
        return 1
    else:
        return fibonacci_cache(n-1) + fibonacci_cache(n-2)

# üìå Si n > 1, llama recursivamente a la funci√≥n para calcular fibonacci(n-1) + fibonacci(n-2).
# üìå Gracias a @lru_cache, no vuelve a calcular los valores repetidos.

'''
‚ö†Ô∏è ¬øSe usa en backend profesional?
üîπ En producci√≥n NO se usa lru_cache porque la cach√©:

- Se borra al reiniciar el servidor.
- No es compartida entre m√∫ltiples instancias en backend distribuido.

‚úÖ Alternativa moderna en backend: Usar Redis en FastAPI o Django.

üîπ   Uso en backend profesional: ---> 10%
‚ö†Ô∏è **Advertencia:** El decorador `@lru_cache` es √∫til para **memorizaci√≥n en c√°lculos repetitivos**, pero **en backend real se usan Redis o bases de datos cacheadas en lugar de esto**.  

‚úÖ **√ösalo para:**  
‚úîÔ∏è Optimizar funciones de alto costo computacional en scripts peque√±os.  

‚ùå **Ev√≠talo cuando:**  
‚ùå Necesites persistencia real de cach√© en backend (usa Redis, Memcached o FastAPI con `Depends`).  
‚ùå Quieras manejar cach√© en m√∫ltiples instancias de un servidor.  

üìå **Conclusi√≥n:** Solo aprende lo justo sobre `@lru_cache`. **En backend real, usa Redis para almacenamiento en cach√© eficiente.**
'''